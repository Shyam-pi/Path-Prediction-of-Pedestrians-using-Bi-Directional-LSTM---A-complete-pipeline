{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Thesis_Prediction_Training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyfFc8VufUyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "################################################################################\n",
        "# INSTALL CONDA ON GOOGLE COLAB\n",
        "################################################################################\n",
        "! wget https://repo.anaconda.com/miniconda/Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
        "! chmod +x Miniconda3-py37_4.8.2-Linux-x86_64.sh\n",
        "! bash ./Miniconda3-py37_4.8.2-Linux-x86_64.sh -b -f -p /usr/local\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io41rcX8paFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mounting google drive for workspace\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIx1R_o2p0mk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Change directory to working folder (change address to your own folder's address)\n",
        "%cd /content/gdrive/My Drive/Colab Notebooks/BE Thesis/Prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R4_R4GqNv5r",
        "colab_type": "text"
      },
      "source": [
        "Paste the Keras-LSTM-Trajectory-Prediction folder in the working folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNHJgcCDfPLK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd Keras-LSTM-Trajectory-Prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu-GjP1lfs9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Installing dependencies\n",
        "!conda env update -f environment.yml "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9rrVViuqeko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install --upgrade progressbar2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odcaYJnZasER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Test with a random set of trajectories (No need to execute)\n",
        "!python load.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYjbodmoHRQC",
        "colab_type": "text"
      },
      "source": [
        "# **Workflow of the model training:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr3Y-2dFJFiL",
        "colab_type": "text"
      },
      "source": [
        "1. Extract raw object trajectories obtained from a previous Detection + Tracking processing pipeline.\n",
        "In order to train the trajectory forcasting model, you need several .csv files containing raw trajectories obtained from a previous Detection + Tracking processing pipeline, a D+T pipeline for short. The D+T pipeline is in charge of supplying raw D+T trajectories packed in a .csv file with an specific output format. All of the previously described .csv files must be in a folder for further use by dataset_creator utility tool.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VvZZo1UJIw3",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "2. Pack all trajectories in a convenient raw_paths.h5 file\n",
        "Once you have all D+T raw trajectories on an user-defined cache_folder, use dataset_creator utility tool to pack all raw trajectories into a raw_paths.h5 file located at output_folder = full/path/to/raw_paths.h5: .\n",
        "The resulting raw_paths.h5 will contain several object trajectories for furter steps. cache_folder is where all the raw CSV files are given as inputs. output_folder is where the create .h5 file will be stored."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h05AT4DmqKkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd dataset-creator/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igFeUainMOha",
        "colab_type": "text"
      },
      "source": [
        "*Usage notes for dataset-creator.py:*\n",
        "\n",
        "\n",
        "```\n",
        "dataset-creator [-h] [-a] input_directory output\n",
        "\n",
        "positional arguments:\n",
        "\n",
        "\tinput_directory  Path of a directory with CSV files to extract tracks.\n",
        "\n",
        "\toutput           Path of the output training dataset file with .hdf5 extension.\n",
        "\n",
        "optional arguments:\n",
        "\n",
        "\t-h, --help       show this help message and exit\n",
        "  \n",
        "\t-a, --append     Flag to indicate that an existing HDF5 file can be used and new datasets should be appended to it.\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6O9Mpcgn0cn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python dataset-creator.py /content/gdrive/My\\ Drive/Colab\\ Notebooks/BE\\ Thesis/Prediction/Keras-LSTM-Trajectory-Prediction/cache_folder /content/gdrive/My\\ Drive/Colab\\ Notebooks/BE\\ Thesis/Prediction/Keras-LSTM-Trajectory-Prediction/output_folder/raw_paths.hdf5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDxNcxZsJOBh",
        "colab_type": "text"
      },
      "source": [
        "3. Transform and group all raw paths from raw_paths.h5 into an train_test.h5 dataset\n",
        "All raw paths from raw_paths.h5 will be used for dataset_transformer utility tool in order to generate a train-test dataset for further training and inference tasks. In addition, internal processing, filtering and polynomial trajectory smoothing can be configured by the user using the associated config_transformer.json file. The tool receives a raw_dataset = full/path/to/raw_paths.h5 path, an it will generate a train-test dataset in .h5 format at location out_dataset = full/path/to/train-test.h5 using the config_transformer.json file avalaible at location config = full/path/to/config_transformer.json:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZMp8ScLDD88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/gdrive/My Drive/Colab\\ Notebooks/BE\\ Thesis/Prediction/Keras-LSTM-Trajectory-Prediction/dataset_transformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1smPSeeOAZ4",
        "colab_type": "text"
      },
      "source": [
        "*Usage notes for dataset_transformer.py:*\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "dataset_transformer.py [-h] raw_dataset out_dataset configuration_file\n",
        "\n",
        "positional arguments:\n",
        "\n",
        "  raw_dataset  Path to input raw dataset in .h5 format\n",
        "\n",
        "  out_dataset  Path to output train/test dataset in .h5 format\n",
        "\n",
        "  config       Path to configuration file used for dataset transformer tool.\n",
        "\n",
        "optional arguments:\n",
        "\n",
        "  -h, --help            show this help message and exit\n",
        "  \n",
        "  --norm_target_data    Normalizes or smooths target trajectory data using nth-degree polynomial regression. nth-degree parameter specified in config.json file\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SS5SSJvDBt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python dataset_transformer.py /content/gdrive/My\\ Drive/Colab\\ Notebooks/BE\\ Thesis/Prediction/Keras-LSTM-Trajectory-Prediction/output_folder/raw_paths.hdf5 /content/gdrive/My\\ Drive/Colab\\ Notebooks/BE\\ Thesis/Prediction/Keras-LSTM-Trajectory-Prediction/train_test/train-test.hdf5 /content/gdrive/My\\ Drive/Colab\\ Notebooks/BE\\ Thesis/Prediction/Keras-LSTM-Trajectory-Prediction/dataset_transformer/config_transformer.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrxqZkMJJjDB",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "4. Train and evaluate a Path Prediction LSTM-based neural model\n",
        "By using the LSTM_trainer.py script, the previously generated train-test.h5 dataset, and an user configuration file config_lstm.json you can train your own custom LSTM-based Trajectory prediction model.\n",
        "In addition, in order to evaluate the performance of the trained models, use the evaluate_lstm.py script using also the previously generated train-test.h5 dataset, and the same user configuration file config_lstm.json used for training. The evaluate_lstm.py script contains code use for load datasets, load trained models and making inference with them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlCjiWNPGFzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/gdrive/My Drive/Colab\\ Notebooks/BE\\ Thesis/Prediction/Keras-LSTM-Trajectory-Prediction/Train_Test_Scripts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnwLR7r4NrRm",
        "colab_type": "text"
      },
      "source": [
        "# **Training of the proposed model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCjaznZzKwvm",
        "colab_type": "text"
      },
      "source": [
        "*Usage notes for LSTM_Trainer.py* : \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "LSTM_trainer.py [-h] dataset  output  config\n",
        "\n",
        "Positional arguments:\n",
        "\n",
        "  dataset -     Path to input train-test dataset in .hdf5 format\n",
        "  \n",
        "  output  -   Path to the output directory where resulting models, graphs and history results are saved.\n",
        "\n",
        "  config   -  Path to configuration file used for training.\n",
        "\n",
        "optional arguments:\n",
        "\n",
        "  -h, --help    -    show this help message and exit\n",
        "\n",
        "  --use_checkpoint - Load and use a previously trained LSTM model to restart training from that file. A new and restored model will be created, preserving original input model.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htdF8u8fGCou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python LSTM_trainer.py /content/gdrive/My\\ Drive/Colab\\ Notebooks/BE\\ Thesis/Prediction/Keras-LSTM-Trajectory-Prediction/train_test/train-test.hdf5 /content/gdrive/My\\ Drive/Colab\\ Notebooks/BE\\ Thesis/Prediction/Keras-LSTM-Trajectory-Prediction/model_output config_lstm.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwXIZUUXgZjj",
        "colab_type": "text"
      },
      "source": [
        "# **Evaluation of the trained model**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kONVDirCLOu6",
        "colab_type": "text"
      },
      "source": [
        "*Usage notes for evaluate_lstm.py:*\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "evaluate_lstm.py [-h] dataset output configuration_file\n",
        "\n",
        "positional arguments:\n",
        "\n",
        "  dataset   -  Path to input test dataset in .hdf5 format\n",
        "\n",
        "  output    -  Path to the output directory where resulting training graphs and \n",
        "  prediction results (model folder) are computed.\n",
        "\n",
        "  config    -  Path to configuration file used for testing.\n",
        "\n",
        "optional arguments:\n",
        "  -h, --help  show this help message and exit\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8Zj4uHtgjVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/gdrive/My Drive/Colab\\ Notebooks/BE\\ Thesis/Prediction/Keras-LSTM-Trajectory-Prediction/Train_Test_Scripts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plkYy4vDgbj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python evaluate_lstm.py  /content/gdrive/My\\ Drive/Colab\\ Notebooks/BE\\ Thesis/Prediction/Keras-LSTM-Trajectory-Prediction/train_test/train-test.hdf5 /content/gdrive/My\\ Drive/Colab\\ Notebooks/BE\\ Thesis/Prediction/Keras-LSTM-Trajectory-Prediction/model_output/ARCH--15i_30o_10sld_norm3_vill_cascade2-_Data-_final_concat512___bs-512_lr-0.01_loss-mae_opt-Ranger_BD-True_BDmrg-concat_amsG-False_DP-False_sw-0.9_sync-1_act-selu_minLR-1e-05_ptc-10_ep-100 config_lstm.json"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}